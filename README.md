# ğŸ¤ Karaoke Sub Tool

**Professioneller Karaoke-Untertitel-Generator mit Video-Editor, KI-Chat und 4 Transkriptions-Backends.**

> **Audio rein â†’ Karaoke-Untertitel raus.** Wortgenau. Automatisch. In Sekunden.

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-0.110+-009688?logo=fastapi&logoColor=white)
![PydanticAI](https://img.shields.io/badge/PydanticAI-v2-E92063?logo=pydantic&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)
![Version](https://img.shields.io/badge/Version-3.2.0-purple)

<table>
<tr>
<td width="50%">

#### ğŸ™ï¸ Transkription â€” 4 Backends, 1 Klick

| Backend | Typ | Highlight |
|---------|-----|-----------|
| **Voxtral** (Mistral AI) | Cloud | Diarization, schnellstes Setup |
| **OpenAI Whisper** | Cloud | BewÃ¤hrte QualitÃ¤t |
| **faster-whisper** | Lokal | 100 % offline, kein API-Key |
| **WhisperX** | Lokal | Forced Alignment, prÃ¤ziseste Wort-Timestamps |

</td>
<td width="50%">

#### âš¡ Auf einen Blick

- ğŸ”¤ **Wort-Level-Timestamps** mit Silben-Approximation
- ğŸ—£ï¸ **Speaker Diarization** â€” wer spricht wann?
- ğŸµ **BPM-Erkennung + Beat-Snap** fÃ¼r rhythmische Untertitel
- ğŸ§  **KI-Korrektur** via PydanticAI (GPT-4o, Claude, Gemini, Mistral)
- ğŸ¬ **Video-Editor** mit Timeline, Preview & Social-Media-Formate
- ğŸ“± **1 Klick â†’ TikTok / Reels / Shorts** (9:16, 1:1, 16:9, 4K)

</td>
</tr>
</table>

### Kernkonzepte

ğŸ™ï¸ **4 Transkriptions-Backends** â€” Voxtral (Mistral AI), OpenAI Whisper, faster-whisper (100 % offline), WhisperX (Forced Alignment)
&nbsp;&nbsp;â†’ Wort-Level-Timestamps Â· Speaker Diarization Â· VAD Â· Vocal Isolation

ğŸ¤– **PydanticAI v2 Chat-Agent** â€” Multi-Provider KI (OpenAI, Anthropic, Mistral, Google) mit 5 Commands + 8 Tools fÃ¼r automatische Textkorrektur, Ãœbersetzung und Segment-Bearbeitung

ğŸ¬ **Integrierter Video-Editor** â€” Multi-Track-Timeline mit Echtzeit-Preview, Untertitel-Overlay, Karaoke-Rendering und Format-Presets (16:9, 9:16, 1:1, 4K)

ğŸ“ **6 Export-Formate** â€” SRT, ASS (mit `\k`/`\kf`/`\ko` Karaoke-Tags), VTT, LRC, TXT, Standalone HTML-Player

ğŸ”§ **Automatische Refinement-Pipeline** â€” CPS-Optimierung, Beat-Snap, Reimschema-Erkennung, Song-Struktur, Lyrics-Alignment, Konfidenz-Report

---

![Karaoke Sub Tool](docs/images/Karaoke-Sub-Tool.png)

## âœ¨ Features

### ğŸ™ï¸ Transkription
- **4 Backends**: Voxtral (Mistral AI), OpenAI Whisper, Local Whisper (faster-whisper), WhisperX
- Wort-Level-Timestamps mit automatischer Silben-Approximation
- Speaker Diarization (Sprechererkennung)
- Voice Activity Detection (WebRTC VAD)
- Vocal Isolation via Demucs

### ğŸ¬ Video-Editor
- Multi-Track-Timeline (Video, Audio, Subtitle, Overlay)
- 3 Video-Skalierungsmodi: FÃ¼llen (Cover), Einpassen (Contain), Strecken (Stretch)
- Format-Vorlagen: 16:9 HD, 4K, 9:16 Vertical, 1:1 Square
- Effekte: Fade, Brightness, Contrast, Blur, Sepia, Vignette, u.v.m.
- Undo/Redo mit bis zu 50 Schritten
- Echtzeit-Vorschau mit Untertitel-Overlay
- ffmpeg-basiertes Rendering

![Video Editor](docs/images/Video-Editor.png)

### ğŸ“ Untertitel-Formate
- **SRT** â€” Standard-Untertitel
- **ASS** â€” Advanced SubStation Alpha mit Karaoke-Tags (`\k`, `\kf`, `\ko`)
- **VTT** â€” WebVTT
- **LRC** â€” Enhanced LRC mit Wort-Level-Tags
- **TXT** â€” Plain Text
- **HTML** â€” Standalone Karaoke-Player

### ğŸ¨ Karaoke-Themes
6 vordefinierte ASS-Presets mit anpassbaren Farben, Outline, Schatten und Fade-Effekten:
- Classic, Neon, High Contrast, Landscape 1080p, Portrait 1080Ã—1920, Mobile Safe

### ğŸ¤– KI-Chat
- PydanticAI v2 mit Multi-Provider-Support (OpenAI, Anthropic, Mistral, Google)
- 5 Commands: `correct`, `punctuate`, `structure`, `translate`, `generate`
- 8 Tools fÃ¼r Segment-Lesen und -Schreiben
- Reasoning-Model-Erkennung (o1, o3, GPT-5, Claude Opus)
- Chat-History pro Job

### ğŸ”§ Refinement-Pipeline
- Text-Bereinigung (Whitespace, Quotes, Custom Dictionary)
- CPS Auto-Fix (Characters Per Second)
- LÃ¼cken-Management (â™ª-Fill, Redistribute)
- BPM-Erkennung + Beat-Snap (Essentia/librosa)
- Reimschema-Erkennung (DE/EN, Rap-optimiert)
- Song-Struktur-Erkennung (Verse/Chorus/Bridge/Hook)
- Textstatistik (TTR, Hapax, Flow-Score)
- Lyrics-Alignment (Greedy Matching)

### ğŸ“Š QualitÃ¤ts-Report
- Konfidenz-Bewertung pro Segment
- Detaillierter JSON/CSV-Report
- Low-Confidence-Markierung in ASS-Dateien

---

##  Installation

### Voraussetzungen

- **Python â‰¥ 3.10** (Ziel: 3.12)
- **ffmpeg** â€” Audio/Video-Verarbeitung
- Mindestens ein Transkriptions-Backend (API-Key oder lokales Modell)

### Setup

```bash
# Repository klonen
git clone https://github.com/Scalino1984/video-editor.git
cd video-editor

# Virtual Environment erstellen
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt
```

### API-Keys konfigurieren

Erstelle eine `.env`-Datei im Projektverzeichnis:

```env
# Transkription (mindestens einen Key)
MISTRAL_API_KEY=your-mistral-key        # Voxtral Backend
OPENAI_API_KEY=sk-your-openai-key       # OpenAI Whisper Backend
HF_TOKEN=hf_your-token                  # WhisperX Diarization

# KI-Chat (optional)
AI_MODEL=openai:gpt-4o                  # oder anthropic:claude-sonnet-4, mistral:*, google:*
```

### Optionale AbhÃ¤ngigkeiten

```bash
# WhisperX (prÃ¤ziseste Wort-Timestamps)
pip install whisperx torch torchaudio

# Local Whisper (kein API-Key nÃ¶tig)
pip install faster-whisper

# Vocal Isolation
pip install demucs

# BPM-Erkennung
pip install essentia  # bevorzugt
pip install librosa   # Fallback
```

---

## ğŸ–¥ï¸ Verwendung

### Server (WebUI + Video-Editor)

```bash
# Direktstart
python main.py

# Mit Optionen
python main.py --host 0.0.0.0 --port 8000 --reload

# Via Server-Manager
./server.sh start
./server.sh status
./server.sh log
./server.sh stop
```

Ã–ffne im Browser:
- **WebUI**: [http://localhost:8000](http://localhost:8000)
- **Video-Editor**: [http://localhost:8000/editor](http://localhost:8000/editor)

### CLI

```bash
# Transkription
python -m src.cli transcribe --input audio.mp3 --backend voxtral --ass

# Batch-Verarbeitung
python -m src.cli transcribe --input ./songs/ --backend whisperx --ass --lrc

# Refinement
python -m src.cli refine --input subs/ --cps 18

# Export mit Karaoke-Tags
python -m src.cli export --input subs/ --karaoke-mode kf --preset neon

# Preview-Clip rendern
python -m src.cli preview --input song.srt --audio song.mp3

# Interaktives MenÃ¼
python -m src.cli menu
```

---

## âš™ï¸ Konfiguration

Die Konfiguration erfolgt Ã¼ber `config.yaml` im Projektverzeichnis:

```yaml
preprocess:
  vad:
    enabled: true
    aggressiveness: 2          # 0-3
  normalize:
    enabled: true
    target_lufs: -16.0
  vocal_isolation:
    enabled: false

transcription:
  backend: voxtral             # voxtral | openai_whisper | local_whisper | whisperx
  language: auto               # de | en | auto
  word_timestamps: auto

refinement:
  cps: 18.0                    # max Characters Per Second
  min_duration: 1.0
  max_duration: 6.0
  max_chars_per_line: 42

karaoke:
  mode: kf                     # k (fill) | kf (fade) | ko (outline wipe)
  fade_in_ms: 150
  fade_out_ms: 100

theme:
  preset: classic              # classic | neon | high_contrast | ...
```

CLI-Overrides via Dot-Notation:
```bash
python -m src.cli transcribe --input audio.mp3 \
  --set transcription.backend=whisperx \
  --set refinement.cps=20
```

---

## ğŸ“ Projektstruktur

```
main.py                          â† FastAPI-App + Uvicorn
server.sh                        â† Server-Manager-Script
config.yaml                      â† Konfiguration
src/
  cli.py                         â† Typer CLI
  api/
    models.py                    â† Pydantic v2 Schemas
    routes.py                    â† REST-API (60+ Endpunkte)
    tasks.py                     â† Background-Jobs (SSE, Undo/Redo)
  transcription/
    voxtral.py                   â† Mistral AI Voxtral
    openai_whisper.py            â† OpenAI Whisper API
    local_whisper.py             â† faster-whisper (lokal)
    whisperx_backend.py          â† WhisperX + Forced Alignment
  refine/
    alignment.py                 â† Wort-Timestamp-Approximation
    segmentation.py              â† Split/Merge/Gaps/Line-Breaks
    beatgrid.py                  â† BPM-Erkennung + Beat-Snap
    confidence.py                â† QualitÃ¤ts-Report
    lyrics_align.py              â† Lyricsâ†’ASR Alignment
    rhyme.py                     â† Reimschema-Erkennung
    structure.py                 â† Song-Struktur-Erkennung
  export/
    srt_writer.py                â† SRT
    ass_writer.py                â† ASS mit Karaoke-Tags
    vtt_writer.py                â† WebVTT
    lrc_writer.py                â† Enhanced LRC
    karaoke_html.py              â† Standalone HTML-Player
    karaoke_tags.py              â† ASS \k/\kf/\ko Generator
    themes.py                    â† 6 ASS-Presets
  ai/
    chat.py                      â† PydanticAI v2 Agent
    routes.py                    â† Streaming-Chat-API
  video/
    editor.py                    â† Timeline-Editor
    editor_routes.py             â† Editor REST-API
    render.py                    â† ffmpeg Video-Rendering
  static/
    index.html                   â† WebUI SPA
    editor.html                  â† Video-Editor SPA
data/
  uploads/                       â† Hochgeladene Dateien
  output/{job_id}/               â† Job-Artefakte
  editor/                        â† Editor Assets & Renders
  library.sqlite                 â† Library-Datenbank
```

---

## ğŸ”Œ API

Die REST-API lÃ¤uft unter `/api/` mit 60+ Endpunkten. VollstÃ¤ndige Dokumentation:

- **Swagger UI**: [http://localhost:8000/docs](http://localhost:8000/docs)
- **ReDoc**: [http://localhost:8000/redoc](http://localhost:8000/redoc)

### Wichtige Endpunkte

| Methode | Pfad | Beschreibung |
|---------|------|-------------|
| `POST` | `/api/transcribe` | Neuen Transkriptions-Job starten |
| `GET` | `/api/jobs/{id}` | Job-Status abfragen |
| `GET` | `/api/jobs/{id}/segments` | Segmente laden |
| `PUT` | `/api/jobs/{id}/segments/{idx}` | Segment bearbeiten |
| `POST` | `/api/jobs/{id}/export` | Export auslÃ¶sen |
| `POST` | `/api/chat/{id}` | KI-Chat (NDJSON Streaming) |
| `POST` | `/api/editor/projects` | Editor-Projekt erstellen |
| `POST` | `/api/editor/projects/{id}/render` | Video rendern |

---

## ğŸ§ª Tests

```bash
# Alle Tests
pytest tests/

# Einzelne Test-Suites
pytest tests/test_core.py -v        # Core (Serialisierung, Writer, Refinement)
pytest tests/test_library.py        # Library-DB
pytest tests/test_v31.py            # v3.1 Features

# Mit Coverage
pytest tests/ --cov=src --cov-report=html
```

Aktuell: **107 Tests**, alle bestanden.

---

## ğŸµ Pipeline

```
Audio â†’ Vocal Isolation? â†’ WAV 16kHz â†’ Normalize? â†’ VAD?
  â†’ Transkription â†’ Text Cleanup â†’ Word Timestamps â†’ Segmentation
  â†’ Lyrics Alignment? â†’ BPM Snap? â†’ KI-Korrektur?
  â†’ Export (SRT/ASS/VTT/LRC/TXT/HTML)
  â†’ Konfidenz-Report â†’ Preview? â†’ Library
```

---

## ğŸ¹ Transkriptions-Backends

| Backend | API-Key | Word-Timestamps | Diarization | Bemerkung |
|---------|---------|-----------------|-------------|-----------|
| **Voxtral** | `MISTRAL_API_KEY` | âœ… | âœ… | Standard-Backend |
| **OpenAI Whisper** | `OPENAI_API_KEY` | âœ… | âŒ | `whisper-1` Modell |
| **Local Whisper** | â€” | âœ… | âŒ | Kein API-Key, GPU optional |
| **WhisperX** | `HF_TOKEN` (optional) | âœ…âœ… | âœ… | Forced Alignment, prÃ¤ziseste Timestamps |

---

## ğŸ¨ Video-Editor

Der integrierte Video-Editor ermÃ¶glicht:

- Drag & Drop von Video, Audio, Untertitel und Overlay auf die Timeline
- Echtzeit-Vorschau mit Untertitel-Rendering
- 3 Video-Skalierungsmodi pro Projekt
- Untertitel-Styling (Font, GrÃ¶ÃŸe, Farbe, Outline, Position, Zeilen)
- KI-Assistent fÃ¼r Clip-Bearbeitung
- Rendering zu MP4 mit libx264

### Format-Presets

| Preset | AuflÃ¶sung | Verwendung |
|--------|-----------|-----------|
| 16:9 HD | 1920Ã—1080 | YouTube, Standard |
| 4K | 3840Ã—2160 | Ultra HD |
| 9:16 Vert | 1080Ã—1920 | TikTok, Reels, Shorts |
| 1:1 Square | 1080Ã—1080 | Instagram |

---

## ğŸ¤ Mitwirken

BeitrÃ¤ge sind willkommen! Bitte beachte:

1. **Code-Sprache**: Englisch (Code + Kommentare), Deutsch (UI + Prompts)
2. **Linter**: `ruff` mit 120 Zeichen ZeilenlÃ¤nge
3. **Type-Hints**: Ãœberall, `X | None` statt `Optional[X]`
4. **Tests**: `pytest` mit `asyncio_mode = "auto"`
5. **Imports**: `from __future__ import annotations` in jeder Datei

```bash
# Linter
ruff check src/ tests/
ruff format src/ tests/

# Tests
pytest tests/ -v
```

---

## ğŸ“„ Lizenz

MIT License â€” siehe [LICENSE](LICENSE) fÃ¼r Details.

---

## ğŸ™ Credits

- [FastAPI](https://fastapi.tiangolo.com/) â€” Web-Framework
- [Typer](https://typer.tiangolo.com/) â€” CLI-Framework
- [PydanticAI](https://ai.pydantic.dev/) â€” KI-Agent-Framework
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper) â€” Lokale Transkription
- [WhisperX](https://github.com/m-bain/whisperX) â€” Forced Alignment
- [Demucs](https://github.com/facebookresearch/demucs) â€” Vocal Isolation
- [Essentia](https://essentia.upf.edu/) â€” BPM-Erkennung
- [Rich](https://rich.readthedocs.io/) â€” Terminal-Formatierung
- [ffmpeg](https://ffmpeg.org/) â€” Audio/Video-Verarbeitung
